#[global]
#db_version = v1_3
#db_purpose = best
#primary_name = CeEndpoint
#digitype = Extracted
#release_v_dts = ae
#release_v_stops = p
#release_v_dig = ae
#release_v_reco = ae
#digidb_version = v1_3
#recodb_version = v1_3
#stream = Triggered

[stage_mix_par]
global.stage_name = %(primary_name)s%(digitype)s
global.desc = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

job_output_7.addoutput = cnf*.tar
job_setup.prescript_1 = ifdh mkdir_p %(outdir_tar)s/%(stage_name)s/%(desc)s/tar/

executable.name = true
executable_2.name = gen_Mix.sh
executable_2.arg_1 = --primary %(primary_name)s
executable_2.arg_2 = --campaign %(release)s
executable_2.arg_3 = --pver %(release_v_dts)s
executable_2.arg_4 = --mver %(release_v_stops)s
executable_2.arg_5 = --over %(release_v_dig)s
executable_2.arg_6 = --dbpurpose %(db_purpose)s
executable_2.arg_7 = --dbversion %(digidb_version)s
executable_2.arg_8 = --pbeam %(digitype)s
executable_2.arg_9 = --merge 1

job_setup.ifdh_art = False

[stage_mix]
global.stage_name = %(primary_name)s%(digitype)s
global.upload_parfile = True

global.desc = %(release)s%(release_v_dig)s_%(db_purpose)s_%(digidb_version)s
job_output_1.dest = %(logdir_bck)s/%(stage_name)s/%(desc)s/tbz/

job_output_2.addoutput = dig.*.%(stage_name)sTriggered.*art
job_output_2.add_to_dataset = dig.%(submitter)s.%(stage_name)sTriggered.%(desc)s.art
job_output_2.dest = %(outdir_dig_tape)s/%(stage_name)sTriggered/%(desc)s/art

job_output_3.addoutput = dig.*.%(stage_name)sTriggerable.*art
job_output_3.add_to_dataset = dig.%(submitter)s.%(stage_name)sTriggerable.%(desc)s.art
job_output_3.dest = %(outdir_dig_tape)s/%(stage_name)sTriggerable/%(desc)s/art

submit.f_1 = dropbox:////tmp/%(parfile)s

submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
submit.memory = 4000MB

executable.name = true
executable_2.name = run_JITfcl.py

sam_consumer.limit = 1
sam_consumer.schema = https
job_setup.getconfig = True
job_setup.multifile = False
job_setup.setup_local = True

[stage_digi_par]
global.stage_name = %(primary_name)s%(digitype)s
global.desc = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

job_output_7.addoutput = cnf*.tar
job_setup.prescript_1 = ifdh mkdir_p %(outdir_tar)s/%(stage_name)s/%(desc)s/tar/

executable.name = true
executable_2.name = gen_Digitize.sh
executable_2.arg_1 = --primary %(primary_name)s
executable_2.arg_2 = --campaign %(release)s
executable_2.arg_3 = --pver %(release_v_dts)s
executable_2.arg_4 = --over %(release_v_dig)s
executable_2.arg_5 = --digitype %(digitype)s
executable_2.arg_6 = --dbpurpose %(db_purpose)s
executable_2.arg_7 = --dbversion %(db_version)s
executable_2.arg_8 = --field %(bfield)s
executable_2.arg_9 = --merge 10
job_setup.ifdh_art = False

[stage_digi_par_nersc]
global.stage_name = %(primary_name)s%(digitype)s
global.desc = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

job_output_7.addoutput = cnf*.tar
job_setup.prescript_1 = ifdh mkdir_p %(outdir_tar)s/%(stage_name)s/%(desc)s/tar/

#submit.f_1=dropbox:///exp/mu2e/app/users/oksuzian/muse_101323/Production/Scripts/gen_Digitize.sh
#job_setup.prescript_2 = chmod +x ${CONDOR_DIR_INPUT}/*

executable.name = true
#executable_2.name = \\\\\\\$CONDOR_DIR_INPUT/gen_Digitize.sh
executable_2.name = gen_Digitize.sh
executable_2.arg_1 = --primary %(primary_name)s
executable_2.arg_2 = --campaign %(release)s
executable_2.arg_3 = --pver %(release_v_dts)s
executable_2.arg_4 = --over %(release_v_dig)s
executable_2.arg_5 = --digitype %(digitype)s
executable_2.arg_6 = --dbpurpose %(db_purpose)s
executable_2.arg_7 = --dbversion %(db_version)s
executable_2.arg_8 = --field %(bfield)s
executable_2.arg_9 = --merge 10
job_setup.ifdh_art = False

#NERSC specifics
submit.OS=SL7
submit.resource-provides=usage_model="OFFSITE"
submit.site="NERSC-Perlmutter-CPU"
submit.role='Production'
submit.append_condor_requirements=''

[stage_digi]
global.stage_name = %(primary_name)s%(digitype)s
global.upload_parfile = True

global.desc = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s
global.release_v_o = %(release_v_dig)s

job_output_1.dest = %(logdir_bck)s/%(stage_name)s/%(desc)s/tbz/

job_output_2.addoutput = dig.*.%(stage_name)sTriggered.*art
job_output_2.add_to_dataset = dig.%(submitter)s.%(stage_name)sTriggered.%(desc)s.art
job_output_2.dest = %(outdir_dig_tape)s/%(stage_name)sTriggered/%(desc)s/art

job_output_3.addoutput = dig.*.%(stage_name)sTriggerable.*art
job_output_3.add_to_dataset = dig.%(submitter)s.%(stage_name)sTriggerable.%(desc)s.art
job_output_3.dest = %(outdir_dig_tape)s/%(stage_name)sTriggerable/%(desc)s/art

global.artRoot_dataset = dig.%(submitter)s%(stage_name)sTriggered.%(desc)s.art,dig.%(submitter)s.%(stage_name)sTriggerable.%(desc)s.art

submit.f_1 = dropbox:////tmp/%(parfile)s

submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
executable.name = true

executable_2.name = run_JITfcl.py

sam_consumer.limit = 1
sam_consumer.schema = https
job_setup.getconfig = True
job_setup.multifile = False
job_setup.setup_local = True

[stage_reco_par]
global.stage_name = %(primary_name)s%(digitype)s%(stream)s
global.desc = %(release)s%(release_v_reco)s_%(db_purpose)s_%(db_version)s

job_output_7.addoutput = cnf*.tar
job_setup.prescript_1 = ifdh mkdir_p %(outdir_tar)s/%(stage_name)s/%(desc)s/tar/

submit.f_1=dropbox:///exp/mu2e/app/users/oksuzian/muse_101323/Production/Scripts/gen_Reco.sh
job_setup.prescript_2 = chmod +x ${CONDOR_DIR_INPUT}/*

executable.name = true
executable_2.name = \\\\\\\$CONDOR_DIR_INPUT/gen_Reco.sh
#executable_2.name = gen_Reco.sh

executable_2.arg_1 = --primary %(primary_name)s
executable_2.arg_2 = --campaign %(release)s
executable_2.arg_3 = --dver %(release_v_dig)s
executable_2.arg_4 = --rver %(release_v_reco)s
executable_2.arg_5 = --dbpurpose %(db_purpose)s
executable_2.arg_6 = --dbversion %(digidb_version)s
executable_2.arg_7 = --digitype %(digitype)s
executable_2.arg_8 = --stream %(stream)s
executable_2.arg_9 = --recodbversion %(recodb_version)s

job_setup.ifdh_art = False

  
[stage_reco]
global.stage_name = %(primary_name)s%(digitype)s%(stream)s
global.upload_parfile = True

global.desc = %(release)s%(release_v_reco)s_%(db_purpose)s_%(db_version)s
global.release_v_o = %(release_v_dig)s
job_output_1.dest = %(logdir_bck)s/%(stage_name)s/%(desc)s/tbz/

job_output_2.addoutput = mcs.*.%(stage_name)s.*art
job_output_2.add_to_dataset = mcs.%(submitter)s.%(stage_name)s.%(desc)s.art
job_output_2.dest = %(outdir_mcs_tape)s/%(stage_name)s/%(desc)s/art
global.artRoot_dataset = mcs.%(submitter)s.%(stage_name)s.%(desc)s.art

submit.f_1 = dropbox:////tmp/%(parfile)s

submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
executable.name = true
executable_2.name = run_JITfcl.py

sam_consumer.schema = https
job_setup.getconfig = True
job_setup.multifile = False
job_setup.setup_local = True