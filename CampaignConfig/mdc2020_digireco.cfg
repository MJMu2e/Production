[stage_digireco_mix_par]
global.desc = %(primary_name)s%(digitype)s
global.dsconf = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

executable.name = gen_Mix.sh
executable.arg_1 = --primary %(primary_name)s
executable.arg_2 = --campaign %(release)s
executable.arg_3 = --pver %(release_v_dts)s
executable.arg_4 = --mver %(release_v_stops)s
executable.arg_5 = --over %(release_v_dig)s
executable.arg_6 = --dbpurpose %(db_purpose)s
executable.arg_7 = --dbversion %(db_version)s
executable.arg_8 = --pbeam %(digitype)s
executable.arg_9 = --merge 1

[stage_digireco_mix]
global.desc = %(primary_name)s%(digitype)s
global.dsconf = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

global.upload_parfile = True
submit.f_1 = dropbox:////tmp/%(parfile)s
submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
submit.memory = 6000MB
submit.disk = 40GB
submit.expected-lifetime = 48h
submit.timeout = 47h

executable_2.name = run_JITfcl.py
job_setup.multifile = True

[stage_digireco_digi_par]
global.desc = %(primary_name)s%(digitype)s
global.dsconf = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

executable.name = gen_Digitize.sh
executable.arg_1 = --primary %(primary_name)s
executable.arg_2 = --campaign %(release)s
executable.arg_3 = --pver %(release_v_dts)s
executable.arg_4 = --over %(release_v_dig)s
executable.arg_5 = --digitype %(digitype)s
executable.arg_6 = --dbpurpose %(db_purpose)s
executable.arg_7 = --dbversion %(db_version)s
executable.arg_8 = --merge 10

[stage_digireco_digi_par_nersc]
global.desc = %(primary_name)s%(digitype)s
global.dsconf = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s

executable.name = gen_Digitize.sh
executable.arg_1 = --primary %(primary_name)s
executable.arg_2 = --campaign %(release)s
executable.arg_3 = --pver %(release_v_dts)s
executable.arg_4 = --over %(release_v_dig)s
executable.arg_5 = --digitype %(digitype)s
executable.arg_6 = --dbpurpose %(db_purpose)s
executable.arg_7 = --dbversion %(db_version)s
executable.arg_8 = --merge 10

#NERSC specifics
submit.OS=SL7
submit.resource-provides=usage_model="OFFSITE"
submit.site="NERSC-Perlmutter-CPU"
submit.role='Production'
submit.append_condor_requirements=''

[stage_digireco_digi]
global.desc = %(primary_name)s%(digitype)s
global.dsconf = %(release)s%(release_v_dig)s_%(db_purpose)s_%(db_version)s
global.release_v_o = %(release_v_dig)s

global.upload_parfile = True
submit.f_1 = dropbox:////tmp/%(parfile)s

submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
executable_2.name = run_JITfcl.py
job_setup.multifile = True

[stage_digireco_reco_par]
global.desc = %(primary_name)s%(digitype)s%(stream)s
global.dsconf = %(release)s%(release_v_rec)s_%(db_purpose)s_%(db_version)s

executable.name = gen_Reco.sh
executable.arg_1 = --primary %(primary_name)s
executable.arg_2 = --campaign %(release)s
executable.arg_3 = --dver %(release_v_dig)s
executable.arg_4 = --rver %(release_v_rec)s
executable.arg_5 = --dbpurpose %(db_purpose)s
executable.arg_6 = --dbversion %(db_version)s
executable.arg_7 = --digitype %(digitype)s
executable.arg_8 = --stream %(stream)s
executable.arg_9 = --recodbversion %(db_version)s

[stage_digireco_reco]
global.desc = %(primary_name)s%(digitype)s%(stream)s
global.release_v_o = %(release_v_rec)s
global.dsconf = %(release)s%(release_v_rec)s_%(db_purpose)s_%(db_version)s

global.upload_parfile = True
submit.f_1 = dropbox:////tmp/%(parfile)s

executable_2.name = run_JITfcl.py

submit.dataset = %(index_dataset)s
submit.n_files_per_job = 1
job_setup.multifile = True

[stage_digireco_reco_list]
global.release_v_o = an

#submit.f_2=dropbox:///exp/mu2e/app/users/oksuzian/muse_080224/Production/Scripts/run_RecoEntuple.py
#job_setup.prescript_14 = chmod +x ${CONDOR_DIR_INPUT}/*
#executable_4.name = \\\\\\\$CONDOR_DIR_INPUT/run_RecoEntuple.py
executable_4.name = run_RecoEntuple.py
executable_4.arg_1 = --rver %(release_v_o)s
submit.n_files_per_job = 1
job_setup.multifile = True
job_setup.setup = OfflineOps
job_setup.setup_1 = mu2etools
env_pass.MOO_CONFIG = simjob-mdc2020

# We don't use etc.*.txt dataset to extract the index
job_setup.postscript_4 = echo "Ignoring index dataset"
job_output_1.addoutput = *.xxx
job_output_2.addoutput = *.xxx
job_output_3.addoutput = *.xxx
job_output_4.addoutput = *.xxx
job_output_5.addoutput = *.xxx
job_output_6.addoutput = *.xxx
job_output_7.addoutput = *.xxx
job_output_8.addoutput = *.xxx

[stage_digireco_evntuple_list]
global.simjob_setup=/cvmfs/mu2e.opensciencegrid.org/Musings/EventNtuple/%(version_entpl)s/setup.sh
#submit.f_2=dropbox:///exp/mu2e/app/users/oksuzian/muse_080224/Production/Scripts/run_RecoEntuple.py
#job_setup.prescript_14 = chmod +x ${CONDOR_DIR_INPUT}/*
executable_4.name = run_RecoEntuple.py
executable_4.arg_1 = --version_reco %(release_v_o)s
executable_4.arg_2 = --version_entpl %(version_entpl)s

submit.n_files_per_job = 1
sam_consumer.limit = 1
job_setup.multifile = True
env_pass.MOO_CONFIG = simjob-mdc2020

# We don't use etc.*.txt dataset to extract the index
job_setup.postscript_4 = echo "Ignoring index dataset"
job_output_1.addoutput = *.xxx
job_output_2.addoutput = *.xxx
job_output_3.addoutput = *.xxx
job_output_4.addoutput = *.xxx
job_output_5.addoutput = *.xxx
job_output_6.addoutput = *.xxx
job_output_7.addoutput = *.xxx
job_output_8.addoutput = *.xxx
